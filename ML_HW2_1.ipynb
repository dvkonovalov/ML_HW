{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26239c33-7daa-4902-9396-e347b109ce42",
   "metadata": {},
   "source": [
    "Копируем в данный файл код наивной байесовской классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d3c945-9a80-4ad6-9fd4-37f997a933b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train(samples):\n",
    "    classes, freq = defaultdict(lambda:0), defaultdict(lambda:0)\n",
    "    for feats, label in samples:\n",
    "        classes[label] += 1                 # count classes frequencies\n",
    "        for feat in feats:\n",
    "            freq[label, feat] += 1          # count features frequencies\n",
    "\n",
    "    for label, feat in freq:                # normalize features frequencies\n",
    "        freq[label, feat] /= classes[label]\n",
    "    for c in classes:                       # normalize classes frequencies\n",
    "        classes[c] /= len(samples)\n",
    "    return classes, freq                    # return P(C) and P(O|C)\n",
    "\n",
    "def classify(classifier, feats):\n",
    "    classes, prob = classifier\n",
    "    return min(classes.keys(),              # calculate argmin(-log(C|O)) -> argmax(P(C|O))\n",
    "        key = lambda cl: -log(classes[cl]) + \\\n",
    "            sum(-log(prob.get((cl,feat), 1/1000000000)) for feat in feats))\n",
    "\n",
    "def get_features(sample): return (sample[-1]) # get last letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44db72-0c37-4067-a471-9fa7f21d4de7",
   "metadata": {},
   "source": [
    "Открываем файл \"baby-names.csv\" и перемешиваем данные, так как в dataframe сначала идут мальчики, а затем девочки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9cd2c59-8389-49a0-8efe-ed50245cc95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"baby-names.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d191e6-e17f-459d-aa4c-3ec6310e5842",
   "metadata": {},
   "source": [
    "Разделяем данные в выборке на обучающие и тестовые в соотношении 70%/30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76be48d-0a94-4c25-8ff9-45cbe035a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data['name'], data['sex'], train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f920be-fae7-40c1-aca7-ccd0a3b731ea",
   "metadata": {},
   "source": [
    "Обучаем наивную байесовскую классификацию из файла Sem2.ipynb на тренировочном наборе данных. Затем с помощью\n",
    "метода classify() размечаем имена по полу в тестировочном наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6157e5b3-d432-4fee-a06b-9d5ea568006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [(get_features(x_train[index]), y_train[index]) for index, row in x_train.items()]\n",
    "classifier = train(features)\n",
    "pred = [classify(classifier, get_features(row)) for index, row in x_test.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c79137-5846-4d75-8e1d-b9d7dd9d6a71",
   "metadata": {},
   "source": [
    "Посчитаю процент \"правильных ответов\" классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f78147-ed29-4196-adc8-69e80e2b0914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных ответов -  77.83 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Процент правильных ответов - \", round(accuracy_score(y_test, pred)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1265b237-9669-4817-befe-edb5bfdbcd92",
   "metadata": {},
   "source": [
    "Также еще можно построить матрицу ошибок (одна из метрик), чтобы оценить, насколько хорошо \r\n",
    "справился с задачей данный классификато и где именно он ошибся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b006b3-e5b8-4a6a-b9ff-4a05cc89a628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильно определенных мальчиков - 32478. В процентах от мальчиков - 83.907%\n",
      "Неправильно определенных мальчиков - 6229. В процентах от мальчиков - 16.093%\n",
      "Правильно определенных девочек - 27763. В процентах от девочек - 71.752%\n",
      "Неправильно определенных девочек - 10930. В процентах от девочек - 28.248%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(y_test, pred)\n",
    "\n",
    "print(f'Правильно определенных мальчиков - {matrix[0][0]}. В процентах от мальчиков - {round(matrix[0][0]/(matrix[0][0] + matrix[0][1])*100, 3)}%')\n",
    "print(f'Неправильно определенных мальчиков - {matrix[0][1]}. В процентах от мальчиков - {round(matrix[0][1]/(matrix[0][0] + matrix[0][1])*100, 3)}%')\n",
    "print(f'Правильно определенных девочек - {matrix[1][1]}. В процентах от девочек - {round(matrix[1][1]/(matrix[1][0] + matrix[1][1])*100, 3)}%')\n",
    "print(f'Неправильно определенных девочек - {matrix[1][0]}. В процентах от девочек - {round(matrix[1][0]/(matrix[1][0] + matrix[1][1])*100, 3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f487b23-7125-470c-a315-94306afb9d1a",
   "metadata": {},
   "source": [
    "Как можно видеть, классификатор практически в два раза чаще ошибался в определение девочек и ошибочно принимал их за мальчиков.\n",
    "\n",
    "Модифицирую функцию get_features() таким образом, чтобы в качестве целевого признака бралась другая структура. Попробовав одну первую букву, две первые буквы, первую и последнюю букву вместе, имя целиком, последние две буквы, могу сделать вывод, что вариант с первой и последней буквой наилучший, но все равно практически не отличается от варианта просто с последней буквой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88c6b1f-5ecd-43ea-9af5-7c6927aea6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных ответов -  78.29 %\n"
     ]
    }
   ],
   "source": [
    "def get_features_new(sample): return (sample[0], sample[-1])\n",
    "\n",
    "features = [(get_features_new(x_train[index]), y_train[index]) for index, row in x_train.items()]\n",
    "classifier = train(features)\n",
    "pred = [classify(classifier, get_features_new(row)) for index, row in x_test.items()]\n",
    "print(\"Процент правильных ответов - \", round(accuracy_score(y_test, pred)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14264223-85b0-4e06-af86-599b89d78986",
   "metadata": {},
   "source": [
    "Модифицирую метод classify() так, чтобы вместо логарифмов бралась функция -1/(исходные значения вероятностей), а вместо argmin(...) считался соответственно функционал argmax (..) . Перебрав несколько функций, выяснил, что данная является оптимальной и сравнима с логарифмической."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2750644d-3c81-49f8-b5c7-bef24758effa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных ответов -  77.83 %\n"
     ]
    }
   ],
   "source": [
    "def classify_new(classifier, feats):\n",
    "    classes, prob = classifier\n",
    "    return max(classes.keys(),              # calculate argmin(-log(C|O)) -> argmax(P(C|O))\n",
    "        key = lambda cl: -1/(classes[cl]) + \\\n",
    "            sum(-1/prob.get((cl,feat), 1/1000000000) for feat in feats))\n",
    "\n",
    "features = [(get_features(x_train[index]), y_train[index]) for index, row in x_train.items()]\n",
    "classifier = train(features)\n",
    "pred = [classify_new(classifier, get_features(row)) for index, row in x_test.items()]\n",
    "print(\"Процент правильных ответов - \", round(accuracy_score(y_test, pred)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c46c9-c57e-4a79-b590-4ca5113d92ce",
   "metadata": {},
   "source": [
    "Доля правильных ответов алгоритма после модификации целевого признака и изменения метода classify() практически не изменилась, но если использовать другие варианты, то результат значительно ухудшается (до 50-60%). Из чего можно сделать выводы, чтоо выбор целевых признаков и классифицирующей \n",
    "функци очень сильно влияет на результат алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e922042-ce59-4e50-a208-23f5bf7da2c4",
   "metadata": {},
   "source": [
    "Запущу гауссовский классификатор методом из sklearn.naive_bayes и посмотрю процент \"правильных ответов\" на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea63edfe-f36f-49a0-aa99-dadc58a1fa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных ответов -  73.26 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "x_train = x_train.map(lambda x: ord(get_features(x))) # Отбираем последнюю букву в обучающую выборке\n",
    "x_train = x_train.to_numpy().reshape(-1, 1)   # Преобразуем обучающую выборку к массиву numpy\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "x_test = x_test.map(lambda x: ord(get_features(x)))\n",
    "x_test = x_test.to_numpy().reshape(-1, 1)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "\n",
    "y_predict = gnb.predict(x_test)\n",
    "print(\"Процент правильных ответов - \", round(accuracy_score(y_test, y_predict)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01577755-4363-404f-a501-8b37134aa6d2",
   "metadata": {},
   "source": [
    "Как можно видеть, процент \"правильных\" ответов стал меньше, чем в случае наивного байесовского классификатора.\n",
    "Теперь запущу мультиномиальный классификатор методом из sklearn.naive_bayes и посмотрю процент \"правильных ответов\" на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90335d81-c13d-425c-b7e6-ef998efe7614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных ответов -  49.99 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)\n",
    "y_predict = clf.predict(x_test)\n",
    "print(\"Процент правильных ответов - \", round(accuracy_score(y_test, y_predict)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da5005-dfef-4ecc-8187-1705f9c3f91c",
   "metadata": {},
   "source": [
    "Процент правильных ответов стал еще ниже, то есть мультиномиальный классификатор хуже остальных справляется с данной задачей (правильнее даже отметить, что он выдает ответы наугад, так как процент правильных ответов 50% ).\n",
    "В итоге, можно сделать вывод, что самым эффективным классификатором оказался наивный байесовский классификатор. Самым неэффективный классификатор -  мультиномиальный и, соответственно, средний из них гауссовский."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
